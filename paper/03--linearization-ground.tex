We now introduce how to transform a general (i.e., partially ordered) grounded HTN planning problem into a totally ordered one. Given a grounded HTN planning problem, our goal is to linearize every method's task network by adding ordering constraints to them. In particular, in order to decide which ordering constraints are to be added to a task network, we want to \emph{infer} the precondition and effects of each compound task in the task network. % from all primitive tasks into which it can be decomposed. 

The reason for doing such inference is that our intent is to let every linearized task network be able to be decomposed into at least one executable action sequence (though it is not always possible), and we thus want to capture the state transition information about the action sequences that can be obtained from the task network. In other words, we want to acquire the knowledge that for each compound task $c$ in the task network, which propositions are required so that there is an action sequence $\pi \in \seqSet{c}$ this is executable (i.e., the precondition of $c$), and which propositions will be obtained (or deleted) by applying such a $\pi$ (i.e., the effects of $c$). % which can be loosely acquired by inferring the preconditions and the effects of the compound tasks. 

Thus, generally speaking, our linearization approach consists of two phases. The first one is to infer preconditions and effects of compound tasks, and the second one is to add ordering constraints to each method's task network according to those inferred preconditions and effects. We now elaborate these two phases in detail as follows.

\subsection{Inferring Preconditions and Effects}
We present two approaches for inferring preconditions and effects of compound tasks. The first one is a polynomial time procedure that overly \emph{approximates} a compound task $c$'s precondition and effects by collecting all propositions that are in some action's precondition (or effects) into which can be decomposed from $c$. The second inference approach is developed by \shortCite{ConnyPreEstimation} which can extract more precise preconditions and effects but also has higher computational complexity. 

For the purpose of simplicity, for every $t \in \pTasks{} \cup \cTasks{}$, we extend the previous notations to let $\preCondExt{t}$, $\effPosExt{t}$, $\effNegExt{t}$ refer to the (inferred) precondition, positive effects, and negative effects of the task $t$, respectively.

\paragraph{Simple Inference} For a compound task $c$, our simple inference approach collects a proposition into $c$'s precondition (or effects) if it is in some action's precondition (or effects) into which can be decomposed from $c$. 
% In other words, the approach collects all \emph{possible} propositions that can be in the precondition and effects of a compound task. %
Concretely, for a task $t \in \pTasks{} \cup \cTasks{}$, the inference is done inductively as follows:
\begin{description}
    \item[Basis:] If $t \in \pTasks{}$, $\preCondExt{t} = \preCond{t}$, $\effPosExt{t} = \effPos{t}$, and $\effNegExt{t} = \effNeg{t}$.
    \item[Induction:] If $t \in \cTasks{}$, for each $X \in \left\{\mathtt{prec}, \mathtt{eff}^{+}, \mathtt{eff}^{-}\right\}$,
    \begin{displaymath}
        X(t) = \bigcup_{\substack{(t, (T, \parOrd{}, \alpha)) \in \methods{}\\t' \in T}}X(t')
    \end{displaymath}
\end{description}

One can easily recognize that the inductive procedure can be done in polynomial time because it will terminate after visiting all methods in $\methods{}$.  

\paragraph{Complex Inference} Compared with the simple inference approach, the one by \shortCite{ConnyPreEstimation} extracts more accurate precondition and effects for each compound task.

% TODO: maybe define a notation for the set of action sequences obtained from a compound tasks.
In particular, while inferring the effects (positive or negative) of a compound task $c$, the approach by \shortCite{ConnyPreEstimation} can further rule out some propositions that are \emph{impossible} to occur in \emph{any} state resulting from executing an action sequence into which can be decomposed from $c$. That is, the effects $\effPosExt{c}$ or $\effNegExt{c}$ found by this complex approach will form a \emph{subset} of the one found by the simple inference approach described above. For more technical details about this approach, we refer to the authors' original work.

\subsection{Linearizing Methods}

We now move on to introduce how to linearize a method's task network. Bearing the inferred preconditions and effects of the compound tasks in a task network, we could phrase this task as follows. Given a task network $tn = (T, \parOrd{}, \alpha)$, we want to find a linearization $\langle t_{1} \cdots t_{|T|} \rangle$ of $tn$ respecting $\parOrd{}$ such that there exists a state sequence $\langle s_{1} \cdots s_{|T| - 1} \rangle$ in which $s_{1} = \effPosExt{\alpha(t_{1})}$, and for each $1 \leq i \leq |T| - 1$, $\preCondExt{t_{i + 1}} \subseteq s_{i}$ and $s_{i} \to_{\alpha(t_{i + 1})} s_{i + 1}$, namely we can view each compound task as an ``action'' and interpret the linearization problem as the problem of finding an \emph{executable} linearization of a task network consisting solely of actions.