\def\year{2022}\relax
%File: formatting-instructions-latex-2022.tex
%release 2022.1
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage[submission]{aaai23}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
% \usepackage{algorithm}
% \usepackage{algorithmic}
% \usepackage[noend]{algpseudocode}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
%\floatstyle{ruled}
%\newfloat{listing}{tb}{lst}{}
%\floatname{listing}{Listing}

%
% user import packages
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{paralist}
\usepackage{todonotes}
\usepackage{booktabs}
\usepackage{varwidth}
\usepackage{xcolor}
\usepackage{booktabs} 
\usepackage[ruled, noend, linesnumbered]{algorithm2e}  
\usepackage{csquotes}
\usepackage{subcaption}
\usepackage{amssymb} 
\usepackage{tikz}

\nocopyright
%
% PDF Info Is REQUIRED.
% For /Title, write your title in Mixed Case.
% Don't use accents or commands. Retain the parentheses.
% For /Author, add all authors within the parentheses,
% separated by commas. No accents, special characters
% or commands are allowed.
% Keep the /TemplateVersion tag as is
\pdfinfo{
/Title (Ordnung ist das halbe Leben -- Establishing Totally Ordered HTN
Planning Problems is Half the Job (to Getting them Solved More Efficiently))
/Author (Anonymous)
/TemplateVersion (2022.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai22.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
% \iffalse


\newtheorem{theorem}{Theorem} 

\newcommand{\Eff} {\ensuremath{\mathit{eff}}}  % example command without arguments
\newcommand{\Pre} {\ensuremath{\mathit{pre}}}  % (again)

\newcommand{\Add} {\ensuremath{\mathit{add}}}
\newcommand{\Del} {\ensuremath{\mathit{del}}}
\newcommand{\PreS} {\ensuremath{\mathit{pre^{*}}}}
\newcommand{\AddS} {\ensuremath{\mathit{add^{*}}}}
\newcommand{\DelS} {\ensuremath{\mathit{del^{*}}}}
\newcommand{\singlePrec} {\ensuremath{\mathit{ \mathord{\prec} }}}
\newcommand{\tasks} {\ensuremath{\mathit{tasks}}}

%\newcommand{\EffPlus} {\ensuremath{\mathit{eff^{+}_{*}}}}
%\newcommand{\EffMinus} {\ensuremath{\mathit{eff^{-}_{*}}}}
\newcommand{\PossEffPlus} {\ensuremath{\mathit{\textit{poss-eff}^{+}_{*}}}}
\newcommand{\PossEffMinus} {\ensuremath{\mathit{\textit{poss-eff}^{-}_{*}}}}

%\newcommand{\RelEffPlus} {\ensuremath{\mathit{\textit{eff}^{\emptyset +}_{*}}}}
%\newcommand{\RelEffMinus} {\ensuremath{\mathit{\textit{eff}^{\emptyset -}_{*}}}}
\newcommand{\RelPossEffPlus} {\ensuremath{\mathit{\textit{poss-eff}^{\emptyset +}_{*}}}}
\newcommand{\RelPossEffMinus} {\ensuremath{\mathit{\textit{poss-eff}^{\emptyset -}_{*}}}}


\author {
    Submission
}
\affiliations{
    Anonymous
}
% \fi


%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{Ordnung ist das halbe Leben -- Establishing Totally Ordered HTN
	Planning Problems is Half the Job (to Getting them Solved More Efficiently)}
\author {
    % Authors
    Anonymous

}
\affiliations {
    % Affiliations
    Anonymous
}
\fi

\title{Ordnung ist das halbe Leben -- Establishing Totally Ordered HTN
	Planning Problems is Half the Job (to Getting them Solved More Efficiently)}

% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
% \usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract} 
HTN planning is in general undecidable, yet there exist efficient
planning algorithms. An important subclass is that of totally ordered
HTN planning problems. Not only is this class decidable, but also easier
to handle algorithmically since tasks cannot interleave anymore.
Consequently, several specialized solvers exist, and dedicated tracks at
the International Planning Competition (IPC) in both 2020 and 2023. We
were able to show that almost all currently existing partially ordered
planning benchmarks can be turned into totally ordered ones without
sacrificing solvability. Establishing totally ordered problems in a
preprocessing technique thus allows to use planning systems, heuristics,
pruning techniques (etc.) that are only available for totally ordered
problems. This allows solving problems more efficiently and with
better-informed techniques, at the (little) cost of doing a
preprocessing technique. We show that in only a very few cases
linearization isn't possible, and in all others establishing a total
order pays off \emph{significantly}, thus establishing our technique as
a significant ingredient in the state of the art for solving partially
ordered HTN problems. As a side contribution, we identify a new class of
decidable (EXPTIME-complete) HTN problems, namely those where our
preprocessing technique is guaranteed to be solvability-preserving.
\end{abstract}
 
 

 
 
 
\section{Introduction}
Hierarchical Task Network (HTN) planning is a hierarchical approach to planning. As defined by \cite{HTNSurvey},  %  and \cite{IntroGhallab},
tasks in HTN planning are either primitive, corresponding to an action that can be taken, or compound. HTN problems have a set of methods that specify how one might achieve a given compound task, by decomposing it into a set of sub-tasks. A compound task may even decompose into itself, either directly via a method, or indirectly via a sequence of method applications. If decomposition leads to a sequence of primitive tasks executable from the initial state, then this sequence of actions is a solution to the problem, also known as a \enquote{plan}. 

In totally ordered HTN planning, or TOHTN planning, methods specify a total order on the sub-tasks. In partially ordered HTN planning, or POHTN planning, methods might only specify a partial order on the sub-tasks. 

% Certain kinds of problems might be naturally more suited to being modelled as a partially ordered problem, for example, the actions \enquote{deliver package 1 to city A} and \enquote{deliver package 2 to city B} -- these are essentially unrelated goals in a real transport scenario, and so modelling the problem to require that one task be completed before the other would be unnecessarily limiting the possible solution space. For some problems, such over-specification may remove all valid solutions. 

Many problems might be naturally more suited to being modelled as POHTN problems. However, for \emph{solving} the problem, it is desirable to have additional constraints that reduces the search space, while still preserving at least some of the actual solutions. For example, \cite{ErolHTNExpressivity} proved that POHTN planning is expressive enough to model undecidable problems, such as the language intersection problem of two context-free languages. On the other hand, TOHTN planning is not expressive enough to model undecideable problems. Where this is possible, it results in lower worst-case solving time. Converting the problem to a TOHTN problem allows us to exploit that fact to solve the problem more quickly.

Another benefit of transforming a POHTN problem to a TOHTN problem is that the additional structure to the problem could allow us to deploy specialised algorithms and heuristics for the totally ordered case. % Also, heuristic design is comparably easy for total-order problems due to the missing interaction between tasks.
The drawback to this approach is that, due to the greater expressivity of POHTN planning, there may exist POHTN problems that cannot be solved when converted to a TOHTN problem. 
Fortunately, not every POHTN problem is guaranteed to be undecidable, and so could still be transformed while preserving at least one solution. In fact, the state-of-the-art panda$_\pi$ planner and \cite{HTN2SAS} both use a compilation to classical planning, another decidable planning class.
In this paper we present and investigate an algorithm for converting POHTN problems to TOHTN problems. We prove that when certain criteria are met, it guarantees that at least one solution will be preserved. 
Also, we obtain a new class of decidable problems, namely those that satisfy the above mentioned criterion. Finally, we show that, even when these criteria are not met, very few problems are rendered unsolvable by the transformation, and that it greatly reduces solving time for problems, with gains being bigger for more difficult problems. 


\section{Related Work}
There exist other planners that also compile POHTN problems to decidable planning classes e.g. the planners by \cite{HTN2STRIPS} and HTN2SAS planner by \cite{HTN2SAS} convert POHTN to classical planning problems. To the best of my knowledge, this is the first work that focuses on converting POHTN to TOHTN problems.

\cite{ErolHTNExpressivity} proved that it is NP-complete to decide whether a partially ordered set
of actions has an executable linearization. Our criteria would work on a problem where the only method is for the initial task, and it’s sub-tasks are actions. That is essentially just ordering a partially ordered plan, so the criteria can also identify a proper subset of all partially ordered plans that can be linearized in polynomial time. It can also find a executable linearization for that subset in polynomial time.

\cite{NEBEL1994125} studied various questions regarding partially ordered plans, such as the complexity of plan existence, plan optimisation, possible or necessary truth of properties before or after plan steps, given various constraints on the types of tasks allowed.  \cite{KambhampatiModalTruth1996} studied related questions and criteria under different assumptions.
In the paper by \cite{TanGruningerPOPlanComplexity}, the authors refine \cite{NEBEL1994125}'s results and show the impact of the interaction of preconditions and effects thereby giving a more detailed picture for when finding a linearization for a partially-ordered plan is possible in polynomial time, and when it remains NP-hard. 

Criteria presented in \cite{NEBEL1994125} and \cite{KambhampatiModalTruth1996} and  \cite{TanGruningerPOPlanComplexity} analyse cases where actions have singleton precondition and add lists. This is a less general case than our criteria can cover, but their criteria also correctly identifies some cases as linearizable in polynomial time that our criteria is unable to determine. Thus their results are orthogonal to ours. 

The paper by \cite{DeleteRelaxation, Bercher2021POCLComplexities} generalised \cite{NEBEL1994125}'s as well as \cite{ErolHTNExpressivity}'s result (deciding whether a partially ordered
set of actions possesses an executable linearization) by showing that this problem does not become easier when one is allowed to insert delete-relaxed  actions.


 


\section{Hierarchical Planning Formalism}
Hierarchical task network planning, also known as \textbf{HTN planning}, is one form of hierarchical planning. There are many formalisations for HTN planning. The following one borrows heavily from \cite{HTNSurvey} and \cite{Geier2011TIHTNDecidability}. HTN planning can be partially ordered, also known as POHTN planning, or totally ordered, otherwise known as TOHTN planning. TOHTN planning is a special case of POHTN planning.  % except with the initial task network replaced by a initial compound task. 

A \textbf{Partially Ordered Hierarchical Planning}, also called POHTN, problem P = $(D, S_I, T_I)$
is defined over some domain $D$, 
has an initial state $S_I \in 2^F$, and 
has a initial compound task $T_I$. 
The closed world assumption also holds for HTN planning.

The domain is defined as \textbf{D} = $(F, T_P, T_C, \delta, M)$.
$F$ is the finite set of facts or state variables, $T_P$ is the finite set of all possible primitive task names, $T_C$ is the finite set of all possible compound task names, and
$\delta$ is a mapping from primitive task name to action. Actions in POHTN domain also have preconditions, adds, and delete effects.
$M$ is the finite set of decomposition methods. Each one maps a compound task name to a task network. If $m \in M$, then $m=(c, tn)$, where $c \in T_C$.

A task network \textbf{tn} = $(T, \singlePrec, \alpha)$ consists of
T, which is a finite set of task identifiers (ids); 
$\singlePrec$, which is a partial order over T; and
$\alpha$, which maps task ids $\in$ T to task names in $T_C$ and $T_P$. 

% replacing t  (i.e. $tn_1 \rightarrow_{t,m} tn_2$)
A method $m = (c, tn_m)$ decomposes a task network $tn_1 = (T_1, \singlePrec_1, \alpha_1)$ into
a new task network $tn_2$ by replacing $t$, if and only if $t \in T_1$, $\alpha_1(t) = c$, and $\exists tn' = (T', \singlePrec' \alpha')$ with $tn' \cong tn_m$ and $T' \cap T = \emptyset$ and
\begin{align}
tn_2 :=     &((T_1 \setminus \{t\}) \cup T',    \singlePrec_1 \cup \singlePrec' \cup \singlePrec_X,        \alpha_1 \cup \alpha') \\
\singlePrec_X :=  &\{(t_1, t_2) \in T_1 \times T'  \mid  (t_1,t) \in \singlePrec_1 \} \cup \\
&\{(t_1, t_2) \in T' \times T_1 \mid (t, t_2) \in \singlePrec_1 \}  
\end{align}
In other words, the decomposition of a compound task results in it being removed from the task network and replaced by a copy of the method’s task network. The ordering constraints
on the removed task are inherited by its replacement tasks, as defined by $\singlePrec_X$. 

A \textbf{solution} to an HTN problem is a task network $tn = (T, \prec, \alpha)$ if and only if
tn can be reached via decomposing $tn_I$, all tasks are primitive, ($\forall t \in T: \alpha(t) \in T_P$), and there exists a sequence $\langle t_1, t_2 ... t_n \rangle$ of the task ids in $T$ that agrees with $\prec$ such that the application of that sequence $\langle \alpha(t_1), \alpha(t_2) ... \alpha(t_n) \rangle$ in $S_I$ is executable.

%In other words, there is no goal state for hierarchical planning -- the goal is to find an decomposition of the initial task, then any executable refinement of the resulting decomposition. For any given hierarchical problem, it is trivial to enforce a goal state is met, by replacing the real initial task with a task whose only decomposition is to the real initial task and a primitive task ordered after it whose preconditions are equivalent to any \enquote{goal state} desired. Thus the fact that a goal state is not strictly required is not a restriction to the expressiveness of hierarchical planning. Whereas in classical planning, one only finds any executable sequence of actions to achieve a goal state, so HTN planning poses additional restrictions on which action sequences may be considered.


\textbf{Totally Ordered Hierarchical Planning}, also called TOHTN planning, is the same as partially ordered planning in all respects except the kind of task networks it allows.
%For both planning formalisms, a method $m$ maps a task $t$ to a task network \textbf{tn} = $(T, \prec, \alpha)$. TOHTN planning domains require that $\prec$ must specify a total order between task ids in $T$. This leads to a difference in expressiveness and decideability of TOHTN vs POHTN planning. POHTN planning is more expressive in general (both in terms of plan existence and in terms of computational complexity). 

% As per \cite{LanguageClassificationPlanning}, if regarded from the standpoint of formal grammars, TOHTN planning is exactly as expressive as context free languages, whereas POHTN planning is strictly more expressive than context-free languages, and strictly less expressive than context-sensitive languages.
In terms of complexity classes, \cite{ErolHTNExpressivity} proved that POHTN planning is semi-decidable, whereas \cite{Alford2015TightHTNBounds} proved that, assuming arbitrary recursion, TOHTN planning is 2-EXPTIME-complete with variables, and EXPTIME-complete without. 


\section{Inference of Preconditions and Effects}
The basic linearization process consists of inferring preconditions and effects for compound tasks, inferring additional orderings to the sub-tasks based on the preconditions and effects (inferred or \enquote{real} in the case of primitive tasks) of method sub-tasks. We first attempt to add them all, and then randomly remove orderings that conflict with the originally required orderings, or each other. This random removal of contradicting orderings is called \textbf{\textit{cycle-breaking}}.
 
 
\subsection{Simple Inference of Preconditions and Effects for Compound Tasks (For Lifted and Grounded Domain) }
In a lifted format, tasks and methods accept parameters, referring to any object of a specific type. Thus actions within a method have effects and preconditions that are symmetrical in terms of interactions within the method. 

E.g.\ the task \textit{navigate(waypoint1, waypoint2)} will end up with some set of actions  $\bar{a}$ once decomposed. If you replace the passed parameters \textit{waypoint1} with \textit{waypoint3} and \textit{waypoint2} with \textit{waypoint4}, then \textit{navigate(waypoint3, waypoint4)} will have the same set of actions $\bar{a}$. This is true for all possible tasks by simple induction over the decomposition process.

Thus for each method, we can \enquote{ground} it in the standard way, but using an arbitrary object instead of all objects that exist in the domain.

Specifically, let $\sigma$ be the set of parameters for the method. Then for each parameter of the method, the set of typed objects $\omega$ has one object of the corresponding type, and $|\omega| = |\sigma|$. Then $\sigma(a, \omega)$, the groundings of a transition schema $a$ over $\omega$, corresponds to the ground method obtained by substituting $\sigma$ with the corresponding object of correct type taken from $\omega$.

Where a task accepts two parameters of the same type under different names, it is assumed those are different objects. For example, for \textit{Navigate(pt0, pt1, rover)}, \textit{pt0} and \textit{pt1} are assumed as different objects. % This is illustrated in Figure~\ref{CompoundPreEffForLifted}.

This allows actions to have some ground \enquote{predicate} \textit{at\_waypoint1}, rather than $at(?waypoint)$. The resulting \enquote{predicates} can be used to order the sub-tasks, while groundings for methods are discarded. Only one linearized lifted method per partially-ordered lifted method is produced.

For a grounded method, there are no parameters in a task or method. Methods decompose to specific actions, actions have preconditions and effects on specific state variables. We can then use these to produce a linearized grounded method per grounded method.

In summary, for a lifted domain, where a predicate $f$ accepts parameters $p_1, ..., p_n$, 
$f' = f(o_1, ..., o_n)$, where $o_1, ..., o_n$ are arbitrary objects of the appropriate type. For a grounded model, $f' = f$. The inferred preconditions and effects for a task are then defined as below:
\begin{align*}
& \forall t \in T_P : \PreS(t) := \Pre(t) \\
& \forall t \in T_P : \AddS(t) := \Add(t) \\
& \forall t \in T_P : \DelS(t) := \Del(t)  \\ %  \land
& \forall t \in T_C : \PreS(t) := \{f'  \mid  \exists m \in M  \\
& : m=(t,(T, \singlePrec, \alpha)) \forall t' \in T.  \forall  f \in \PreS(t') \}   \\
& \forall t \in T_C : \AddS(t) := \{f'  \mid  \exists m \in M : \\
& m=(t,(T, \singlePrec, \alpha)) \forall t' \in T.  \forall  f \in \AddS(t') \}   \\
& \forall t \in T_C : \DelS(t) := \{f'  \mid  \exists m \in M : \\
& m=(t,(T, \singlePrec, \alpha)) \forall t' \in T.  \forall  f \in \DelS(t') \}   \\ 
\end{align*}



\subsection{Complex Inference of Preconditions and Effects for Compound Tasks (for Grounded Domain) }
The work by~\cite{ConnyPreEstimation}, details a way to infer executability-relaxed preconditions and effects. Specifically, for a compound task $c$, they are a subset of the mentioned literals described in the Simple Inference section, and a super-set of the actual preconditions and effects for any given refinement and execution of a task $c$.

%State-independent positive and negative effects (cf. their Def. 4) of a compound task c are facts that are added or deleted, resp., by the successful execution of a refinement of c, independent of the state in which the task is executed, i.e.
%$$ \RelEffPlus := ( \bigcap_{s \in E(c)} \bigcap_{s' \in R_s(c)} s') \backslash  \bigcap_{s \in E(c)} s    $$
%$$ \RelEffMinus := \bigcap_{s \in E(c)}  (F \backslash \bigcap_{s' \in R_s(c)} s' ) $$

Possible state-independent effects of a compound task $c$ are not guaranteed to hold (or not hold, resp.,)
after every refinement of c but after at least one:
$$ \PossEffPlus(c) := \bigcup_{s \in E(c)}  ( \bigcup_{s' \in R_s(c)}  s' \backslash s) $$
$$ \PossEffMinus(c) := \bigcup_{s \in E(c)} ((\bigcup_{s' \in R_s(c)} (F \backslash s') \cap s ))$$
if $E(c) \neq \emptyset$ and  $\Pre(c) := \ensuremath{\textit{undef}}$ otherwise.


The set of executability-enabling states of c is
$E(c) = \{s \in 2F  \mid  \exists$ t.o. refinement of $c$ applicable in $s \}$.
The set of resulting states of c w.r.t. some state $s \in 2^F$ is
$R_s(c) = \{s' \in 2^F | \exists$ t.o. refinement appl. in $s$ res. in $s' \}$.

So, the precondition-relaxation of a domain D = $(F, A, C, M)$ is the domain $D' = (F, A', C, M)$
with $A' = \{(\emptyset, add , del ) \mid (prec, add , del ) \in A\}$.

Then, the precondition-relaxed effects $\RelPossEffPlus$, $\RelPossEffMinus$. are defined just like the original ones but based on the precondition-relaxed variant of D.
This means $\RelPossEffPlus$ and $\RelPossEffMinus$ has every effect that $\PossEffPlus$ and $\PossEffMinus$  do, respectively. But
the precondition relaxation can make further refinements executable that produce
effects that can not be achieved in the non-relaxed domain. 
In other words, we can calculate a super-set, that might contain some false candidates, of the real preconditions and effects that might occur after any execution of $c$, i.e.\  $\PossEffMinus \subseteq \RelPossEffMinus$, and $\PossEffPlus  \subseteq \RelPossEffPlus$.

\emph{Mandatory preconditions} of a compound task $c$ are facts that hold in every state for which there exists an executable refinement. So, they are required in every state in which a refinement of c shall be executed: prec(c) := $\cap_{s \in E(c)}  s$
if $E(c) \neq \emptyset$ and $\Pre(c) := \ensuremath{\textit{undef}}$ otherwise.

A fact $f \in F$ is an \emph{executability-relaxed precondition} of $c$ if and only if for all t.o. refinements (ignoring executability of the refinement) $\langle a_0 ... a_n \rangle$ of $c$ there exists an action $a_i$ with $f \in \prec(a_i)$ and there does not exist an action $a_j$ with $j < i$ and $f \in add(a_j)$, where $i, j \in \{0, ..., n\}$.

There exists a polynomial-time algorithm for inferring the executability-relaxed preconditions and precondition-relaxed effects, see \cite{ConnyPreEstimation} for details.
In this paper, we will be utilising both of these, as seen in the next section.
%the precondition-relaxed possible effects, which may hold after at least one refinement of c.

%A fact $f \in F$ is an executability-relaxed precondition of c if and only if for all t.o. refinements (ignoring ex-
%ecutability) 〈a0 . . . an〉 of c there exists an action ai with
%f ∈ prec(ai) and there does not exist an action aj with
%j < i and f ∈ add (aj ), where i, j ∈ {0 . . . n} (cf. Def. 10).
%The exploitation of the relaxed preconditions and effects
%is possible because they possess subset properties with regard to the actual ones so that they do not contain false candidates

\section{Linearization of Methods Using Any Set of Inferred Preconditions and Effects}

\begin{algorithm}[h]
	\caption{Calculation of linearized methods}
	\label{alg:Algorithm1}
	\KwData{$(F, T_P, T_C, \delta, M)$}
	\KwResult{$(F, T_P, T_C, \delta, M)$}
	
	\For {$m=(t, (T_m, \singlePrec, \alpha)) \in M$} 
	{
		\tcc{An edge $(t, t')$ in $G$ means $t$ is ordered before $t'$}  
		$G \gets \singlePrec$ \\
		\label{alg:StartBuildGraph}
		\For{a $\in$ F}{  
			\For{$t \in T_m$}{
				\For{$t' \in T_m$}{
					if $a \in \AddS(t)$ and $a \in \PreS(t')$, add $(t, t')$ to $G$  \\ 
					if $a \in \AddS(t)$ and $a \in \DelS(t')$, add $(t', t)$ to $G$  \\ 
					if $a \in \DelS(t)$ and $a \in \PreS(t')$, add $(t', t)$ to $G$  \\ 
					if $a \in \DelS(t)$ and $a \in \AddS(t')$, add $(t, t')$ to $G$ \\  
				}
			} 
			\label{alg:EndBuildGraph}	
		}	
		\label{alg:StartCycleBreak}
		\While{$G$ has cycles in it}{
			Delete a random ordering in $G$ that is not in $\singlePrec$ \\   % $\PreS, \DelS, \AddS$, rather than $prec$ \;
		}
		\label{alg:EndCycleBreak}
		$\prec'$ = Any linearization of $G$ \\
		\label{alg:TopSort}
		$m' = (tasks(m), \prec', \alpha(t))$ \\
		$M' = M' \cup  \{m'\}$ \\
		
	}
	\Return $D' = (F, T_P, T_C, \delta, M')$ \\
\end{algorithm}



From these inferred preconditions and effects $\PreS(t), \AddS(t), \DelS(t)$, (which may have been derived using the ground or lifted variant), we can run Algorithm~\ref{alg:Algorithm1}.

	
% We can use either sets of preconditions and effects (from either possible inference algorithm) as input to the next linearization phase. Since the effects and preconditions are guaranteed, it may find a linearization that leads to a problem whose solution is yet faster to find,
% or has better make-span than the simple inference. Specifically, the mandatory precondition-relaxed effects, $\RelEffPlus$, $\RelEffMinus$.





\section{Theoretical Properties of Linearization Result}

We now discuss the implications of the above-described linearization procedure.

\begin{theorem}\label{thm:Runtime}
	Given a problem $P = (F, T_P, T_C, \delta, M)$, Algorithm~\ref{alg:Algorithm1} takes polynomial time.
\end{theorem}
\begin{proof}  % ,  network of tasks it can decompose to as a tree of tasks whose edges are between a task and a task it can decompose to, since it excludes previously seen tasks. 
	Let $|T|$ = $|T_P| + |T_C|$.
	
	%The Floyd-Warshall algorithm to calculate transitive closure is used for each method's sub-tasks, resulting in a time complexity of $\mathcal{O}(|M| * |T|^3)$, 
	
	
	To calculate $\PreS, \AddS, \DelS$ for each task $t$. We explore it's compound sub-tasks until we collect all primitive tasks. Then loop over $\PreS, \AddS, \DelS$ for the root $t$, over each fact, over each primitive task in the sub-tree. This is obviously polynomial in terms of $|T|$. %This provides an upper limit of $(3 * |F| * |T_p|) + T_C$. This inference occurs for each compound task, so $((3 * |F| * |T_P|) + |T_C|) * |T_C|$ time at most, or $\mathcal{O}(|F| * |T|^2)$. % we explore all poss (at most $|T_C|$)
	
	Lines~\ref{alg:StartBuildGraph}-\ref{alg:EndBuildGraph} of Algorithm~\ref{alg:Algorithm1} iterates over every method, which iterates over every fact, which iterates over every sub-task in that method, which iterates over every other sub-task in that method. Leading to at most $\mathcal{O}(|M| * |F| * |T|^2)$, since number of sub-tasks per method is upper bounded by $T$.
	
	Cycle-breaking, done by lines \ref{alg:StartCycleBreak} to \ref{alg:EndCycleBreak} can be done via depth-first search per cycle to break, which is also polynomial to $|T|$.
	
	Line~\ref{alg:TopSort} can be done via topological sort of a graph where sub-tasks are nodes, and orderings are edges, which is known to be in $\mathcal{O}(V+E)$ in time. % and $\mathcal{O}(V)$ in space.  
	The number of sub-tasks and edges are upper bounded by $T$, so approximately $\mathcal{O}(|M| * |T|)$.
	
	So the algorithm takes polynomial time.
	%So in total the main algorithm takes: \newline
	%$(|M| * |T|^3)$ +          % Floyd-Warshall
	%$(|M| * |F| * |T|)$  +    % GetPreEff
	%$\mathcal{O}(|M| * |F| * |T|^2)$ +  % desired orderings
	%$(|M| * |T|)$        % topological sort
\end{proof}


\begin{theorem}\label{thm:Soundness}
	Given a POHTN planning problem $P$ and TOHTN problem
	$P'$ obtained from $P$ by using Algorithm~\ref{alg:Algorithm1}
	then the solution set of $P'$, denoted $sol(P')$ is a strict subset of $sol(P)$.
\end{theorem}
\begin{proof}
	The new desired orderings for a method include all of the orderings already required by the method originally. The algorithm then turns the tasks and new desired orderings between them into a directed graph, and the new ordering is produced by performing a topological sort on the nodes of that graph. This means we do not modify the sub-tasks a method produces, just the ordering between them, so the set of plans from the totally ordered method is just a subset of the plans possible from the partially ordered one. Any solution to the linearized problem is then obviously a solution to the original problem.
\end{proof}

\begin{theorem}\label{thm:notCompleteness}
	Given a POHTN planning problem $P$ and TOHTN problem
	$P'$ obtained from $P$ by using Algorithm~\ref{alg:Algorithm1}
	then $sol(P')$ may be empty.
\end{theorem}
\begin{proof}
	This algorithm linearizes all the methods to be totally ordered. Since sub-tasks inherit the orderings of their parents, it's impossible to preserve a solution that requires the interleaving of sub-tasks if their respective parents that are already ordered with respect to each other. This proves that the algorithm can remove some possible action sequences, assuming the original domain was not already totally ordered. Consider the simple example problem:
	The only decomposition for this problem results in the set of un-ordered actions $\{A, B, C\}$.
	If we consider that for the $3!$ linearizations of this set, the only executable one is $A, B, C$. This is impossible to achieve by linearized methods, since ordering either AB before C or C before AB will exclude the solution. 
	Even if we were to produce $k!$ methods for each partially ordered method with $k$ unordered sub-tasks, we would not be able to preserve any solution for this problem.
	This proves that the algorithm can remove all solutions, so Algorithm~\ref{alg:Algorithm1} is not complete. Note that incompleteness already follows from complexity theory as it's theoretically impossible to turn an arbitrary undecidable problem into a decidable one.
	Specifically, solutions that require interleaving of sub-tasks will not be preserved, as the example above demonstrates.
\end{proof}


% The exploitation of the relaxed preconditions and effects
% is possible because they possess subset properties with regard to the actual ones so that they do not contain false candidates.


\begin{description}
	\item[Linearization Criteria] If the linearization process does not find any desired ordering contradicting the existing ones for some method, or in other words, \emph{cycle-breaking} did not occur, that method is said to meet the linearization criteria. If all methods in a problem meet the linearization criteria, then the problem meets the linearization criteria as well. 
\end{description}


%IT ONLY WORKS IF *ALL* METHODS CAN BE CYCLE-BREAKED.


\begin{theorem} \label{thm:RelaxedPreconditions}
	Given a POHTN planning problem $P$ and TOHTN problem $P'$ obtained from $P$ by using Algorithm~\ref{alg:Algorithm1}, \emph{only if $P$, the entire problem meets the linearization criteria},
	then we know executability-relaxed preconditions for any $c$ are indeed the only ones needed to execute any refinement of $c$.
\end{theorem}
\begin{proof}
%	At least in the case where the linearization criteria is met for all methods, we can be assured that the executability-relaxed preconditions actually work for us.
	
	For some method with at least two sub-tasks, $a$ and $b$,
	the desired orderings are to put $a$ with $f \in \Add(a)$ before $b$ with $f \in \Pre(b)$. We're assuming no cycle-breaking, so this was actually achieved. If such a precondition can't be met this way, (such an $a$ does not exist, or the method already enforces that $b$ executes before $a$) by definition it must be in the executability-relaxed preconditions calculated. 

	Therefore, any precondition of $c$'s children that can't be met by placing  other children of $c$ before it is part - so it is indeed a super-set of actual preconditions, assuming no cycle-breaking was needed.
	
	If even one partially ordered method did need cycle-breaking, than of course it means nothing - we may indeed need other preconditions to make refinements of $c$ executable. Then those results no longer hold.
\end{proof}

We use Theorem~\ref{thm:RelaxedPreconditions} as support for the following main result. We will now prove that our algorithm preserves at least one solution as long as Algorithm~\ref{alg:Algorithm1} uses simple inference or preconditions and possible effects from complex inference, and this criterion is met. 

\begin{theorem}\label{thm:SpecialCase}
	Given a POHTN planning problem $P$ and TOHTN problem $P'$ obtained from $P$ by using Algorithm~\ref{alg:Algorithm1}, if $P$ meets the linearization criteria and $sol(P)$ is non-empty, then $sol(P')$ will be non-empty as well.
\end{theorem}
\begin{proof}	
	Assume that there exists a solution in the PO domain. By using the same decomposition sequence in the linearized domain, we can produce the same set of actions as in the PO solution, but with a linearization of the actions decided by the linearized domain. Assume this sequence is $(a_0, a_1, ..., a_n)$. We then prove by induction over the sequence $(a_0, a_1, ..., a_n)$ that it is executable.
	If $(a_0, a_1, ..., a_n)$ is not executable, that means there exists some action $a_k,  0 < k < n$ that is not executable in the corresponding state. The action $a_k$ could only be non-executable, if one or more of its preconditions was not met. Assume one of these unmet preconditions is for existence of the state variable $A$.
	The action $a_k$ must be executable in some linearization of $\{a_0, ..., a_n\}$, as we assumed it was a PO solution. So there must exist an action $a_i$, $0 < i < n$, that will add A. Actions $a_0$ and $a_k$ must have a shared parent p in a Task Decomposition Tree. So p has subtasks $t_0$ and $t_k$ that are parents of $a_0$ and $a_k$ respectively. 
	
	The linearization of this method would have drawn an ordering $(t_i, t_k)$ due to the way the algorithm defines $prec^{*}, add^{*}$ etc. We are assuming that all methods meet the linearization criteria, so $(t_i, t_k)$ should not be required, either directly or via inheritance from parent tasks. This safely enforces $(a_k, a_0)$ ordering in the final TO plan, meaning $a_0$ is not the first action in the resulting total order imposed by the algorithm. In other words, if $a_k$’s precondition could be met by any action $a_i$, $a_i$ would be ordered in front of it. 
	
	If $a_i$ does not exist then $a_k$ can never be executed for any linearization of $\{a_0, ...a_n\}$, contradicting the assumption that this was a PO solution. Since each action in the solution is executable, the entire sequence is executable linearization of actions produced by decomposition of initial task, i.e.\ the solution.
\end{proof}




There are several possible levels of \enquote{completeness} for a problem compilation.
%\begin{enumerate}
\begin{itemize}
	\item all solutions remain 
	\item at least one solution remains 
	\item all optimal solutions remain
	\item at least one optimal solution remains 	
\end{itemize}
%\end{enumerate}
Given what's proven in Theorem~\ref{thm:notCompleteness} and \ref{thm:SpecialCase}, Algorithm~\ref{alg:Algorithm1} guarantees at least one solution remains, if linearization criteria is met. Otherwise, Algorithm~\ref{alg:Algorithm1} makes no completeness guarantees at all -- it may remove all possible solutions. Finally, Algorithm~\ref{alg:Algorithm1} makes no decisions on any metric of optimality, so obviously cannot guarantee completeness that any optimal solutions remain.


\begin{theorem}\label{thm:newClass}
	Problems $P$ that satisfy the linearization criteria form a new class of decidable problems.
\end{theorem}
\begin{proof}
	A problem $P'$ obtained from applying Algorithm~\ref{alg:Algorithm1} to any arbitrary $P$ is a totally ordered problem, which are known to be decidable, as proven by \cite{Alford2015TightHTNBounds}.  
\end{proof}

 



\section{Empirical Evaluation}
We compare the runtime of several state-of-the-art planning systems on some transformed POHTN problems. All problems are taken from two benchmark sets prepared for the International Planning Competition (IPC) 2020. The first set \footnote{https://github.com/panda-planner-dev/ipc2020-domains/tree/master/partial-order} was used in the partially ordered track in the 2020 IPC benchmark, while the second set \footnote{https://github.com/panda-planner-dev/domains/tree/master/partial-order} went un-used for various reasons. Each problem has the standard IPC time limit of 30 minutes. Any grounding and pre-processing time needed is included as part of the 'solving' time. Since the pre-processing may \emph{potentially} remove all solutions, where the planning system can prove that the pre-processing renders a problem unsolvable, we use the remaining time to solve the original problem, called a \textit{re-run}.

\subsection{Hardware and Planning Systems}
The empirical evaluation was conducted on a machine with 30GiB of memory and 4 vCPUs, each with 2 GiB RAM. Recent work by \cite{HTN2SAS} shows that the PO panda$_\pi$, achieved similar coverage and slightly lower IPC score than the best TO planner tested. Also tested is HyperTensioN by \cite{hypertension} an TOHTN solver and the IPC 2020 winner, and Lilotane by \cite{Lilotane} another TOHTN solver and the IPC 2020 runner-up. 

We test the $panda_{\pi}$ solver by \cite{useClassicalHuristicICAPS18,useClassicalHeuristicIJCAI19,progressionsearchJAIR20} configured to use to turn the problem into a classical planning problem (in RC model), and Greedy best first search with visited lists. We try this search with 4 different heuristics: FF by \cite{FF}, Add by \cite{Add}, Filter by \cite{useClassicalHuristicICAPS18} and Landmark-cut by \cite{LM-Cut}. We compare the performance of panda$_\pi$ on the original problem and the pre-processed problem. The same setting is used for re-runs. We also test the latest version of TOHTN planners HTN2SAS, HyperTensioN and Lilotane on the transformed problems. Re-runs use panda$_{\pi}$ with the best heuristic(Add). 
We test both Complex and Simple Inference for linearization.

The results table for both coverage and IPC score can be seen on page \pageref{table:GroundedSimpleIPC}--\pageref{table:GroundedComplexIPC}.
As we can see from those figures, using complex inference results in ?  increase/decrease/similar, coverage and IPC score.
The planner that has achieved the highest overall coverage and IPC score is ? planner.



%The comparison is done for grounded  linearization variant and the lifted linearization variant 1. # \value{page}
 
 
Unfortunately, when using simple inference, there are very few problems for which all partially ordered methods are linearized without conflict.
Fortunately, when using complex inference, most partially ordered methods in all problems are linearized without conflict.
Figure~\ref{ffig:MethodsLinearizedWOCycleBreak} shows the comparison between the two.




%	&& \multicolumn{2}{c}{  \rotatebox{90}{rc2(Add)}} & 
%		\multicolumn{2}{c}{   \rotatebox{90}{rc2(Filter)}} & 
%		\multicolumn{2}{c}{  \rotatebox{90}{rc2(FF)}}
%		& \multicolumn{2}{c}{   \rotatebox{90}{rc2(LMC)}}  
%		& \multicolumn{2}{c}{  \rotatebox{90}{HTN2SAS}}
%		& \multicolumn{2}{c}{  \rotatebox{90}{HyperTensioN}}
%		& \multicolumn{2}{c}{  \rotatebox{90}{Lilotane}} \\ 


\begin{table*}
	\centering
	\caption{Coverage achieved, using Simple Inference on Grounded Problems}
	\label{table:GroundedSimpleCoverage}
	\scalebox{0.8} {
		\begin{tabular}{lccccccccccccccccl} 
			\toprule 
			&& \multicolumn{2}{c}{rc2(Add)} & \multicolumn{2}{c}{rc2(Filter)} & \multicolumn{2}{c}{rc2(FF)} & \multicolumn{2}{c}{rc2(LMC)} \\ 
			\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8} \cmidrule(lr){9-10}  
			& max &PO & TO & PO & TO & PO & TO & PO &\multicolumn{2}{c}{ TO  } \\ 
			\midrule 
			Barman-BDI & 20 & 3.0 & \textbf{10.0} & 3.0 & \textbf{10.0} & 3.0 & \textbf{10.0} & 2.0 &\multicolumn{2}{c}{ \textbf{9.0}  } \\ 
			Monroe Fully Observ.$^{2}$ & 25 & \textbf{25.0} & \textbf{25.0} & 18.0 & \textbf{25.0} & 22.0 & \textbf{25.0} & 15.0 &\multicolumn{2}{c}{ \textbf{16.0}  } \\ 
			Monroe Part. Observ.$^{2}$ & 24 & \textbf{14.0} & \textbf{14.0} & \textbf{7.0} & \textbf{7.0} & 14.0 & \textbf{15.0} & \textbf{10.0} &\multicolumn{2}{c}{ \textbf{10.0}  } \\ 
			PCP$^{17}$ & 17 & \textbf{14.0} & \textbf{14.0} & \textbf{14.0} & \textbf{14.0} & \textbf{14.0} & \textbf{14.0} & \textbf{14.0} &\multicolumn{2}{c}{ \textbf{14.0}  } \\ 
			Rover & 20 & 6.0 & \textbf{20.0} & 4.0 & \textbf{14.0} & 4.0 & \textbf{19.0} & 4.0 &\multicolumn{2}{c}{ \textbf{14.0}  } \\ 
			Satellite & 25 & 24.0 & \textbf{25.0} & 22.0 & \textbf{25.0} & \textbf{25.0} & \textbf{25.0} & 24.0 &\multicolumn{2}{c}{ \textbf{25.0}  } \\  
			Transport & 40 & 12.0 & \textbf{28.0} & \textbf{2.0} & \textbf{2.0} & 13.0 & \textbf{14.0} & 7.0 &\multicolumn{2}{c}{ \textbf{12.0}  } \\ 
			UM-Translog$^{1}$ & 22 & \textbf{22.0} & \textbf{22.0} & \textbf{22.0} & \textbf{22.0} & \textbf{22.0} & \textbf{22.0} & \textbf{22.0} &\multicolumn{2}{c}{ \textbf{22.0}  } \\ 
			Woodworking$^{2}$ & 30 & 13.0 & \textbf{19.0} & 7.0 & \textbf{15.0} & 12.0 & \textbf{20.0} & 9.0 &\multicolumn{2}{c}{ \textbf{15.0}  } \\ 
			\midrule 
			Monroe & 100 & 96.0 & \textbf{100.0} & 79.0 & \textbf{88.0} & 92.0 & \textbf{100.0} & 81.0 &\multicolumn{2}{c}{ \textbf{90.0}  } \\ 
			SmartPhone$^{1}$ & 7 & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} &\multicolumn{2}{c}{ \textbf{5.0}  } \\ 
			Zenotravel & 5 & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} &\multicolumn{2}{c}{ \textbf{5.0}  } \\ 
			\midrule 
			Coverage & 335 & 239.0 & \textbf{287.0} & 188.0 & \textbf{232.0} & 231.0 & \textbf{274.0} & 198.0 &\multicolumn{2}{c}{ \textbf{237.0}  } \\ 
			Norm. coverage & 12 & 8.22 & \textbf{9.95} & 6.85 & \textbf{8.46} & 8.0 & \textbf{9.63} & 7.1 &\multicolumn{2}{c}{ \textbf{8.44}  } \\ 
			\bottomrule 
		\end{tabular}
	}
\end{table*}



\begin{table*}
	\centering
	\caption{IPC score achieved, using Simple Inference on Grounded Problems}
	\label{table:GroundedSimpleIPC}
	\scalebox{0.85} {
		\begin{tabular}{lccccccccccccccccl} 
			\toprule 
			&& \multicolumn{2}{c}{rc2(Add)} & \multicolumn{2}{c}{rc2(Filter)} & \multicolumn{2}{c}{rc2(FF)} & \multicolumn{2}{c}{rc2(LMC)} \\ 
			\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8} \cmidrule(lr){9-10}  
			& max &PO & TO & PO & TO & PO & TO & PO &\multicolumn{2}{c}{ TO  } \\ 
			\midrule 
			Barman-BDI & 1 & 0.08 & \textbf{0.4} & 0.07 & \textbf{0.34} & 0.07 & \textbf{0.36} & 0.05 &\multicolumn{2}{c}{ \textbf{0.22}  } \\ 
			Monroe Fully Observ.$^{2}$ & 1 & \textbf{0.56} & 0.45 & \textbf{0.31} & 0.3 & \textbf{0.46} & 0.41 & \textbf{0.22} &\multicolumn{2}{c}{ 0.18  } \\ 
			Monroe Part. Observ.$^{2}$ & 1 & \textbf{0.31} & 0.25 & \textbf{0.13} & 0.11 & \textbf{0.31} & 0.26 & \textbf{0.17} &\multicolumn{2}{c}{ 0.14  } \\ 
			PCP$^{17}$ & 1 & \textbf{0.82} & \textbf{0.82} & \textbf{0.82} & \textbf{0.82} & \textbf{0.82} & \textbf{0.82} & \textbf{0.82} &\multicolumn{2}{c}{ \textbf{0.82}  } \\ 
			Rover & 1 & 0.29 & \textbf{0.95} & 0.14 & \textbf{0.52} & 0.2 & \textbf{0.78} & 0.16 &\multicolumn{2}{c}{ \textbf{0.48}  } \\ 
			Satellite & 1 & 0.91 & \textbf{1.0} & 0.76 & \textbf{1.0} & 0.99 & \textbf{1.0} & 0.89 &\multicolumn{2}{c}{ \textbf{0.99}  } \\ 
			Transport & 1 & 0.24 & \textbf{0.61} & 0.04 & \textbf{0.05} & 0.27 & \textbf{0.32} & 0.12 &\multicolumn{2}{c}{ \textbf{0.2}  } \\ 
			UM-Translog$^{1}$ & 1 & \textbf{1.0} & \textbf{1.0} & \textbf{1.0} & \textbf{1.0} & \textbf{1.0} & \textbf{1.0} & \textbf{1.0} &\multicolumn{2}{c}{ \textbf{1.0}  } \\ 
			Woodworking$^{2}$ & 1 & 0.38 & \textbf{0.58} & 0.2 & \textbf{0.41} & 0.36 & \textbf{0.57} & 0.27 &\multicolumn{2}{c}{ \textbf{0.39}  } \\ 
			\midrule 
			Monroe & 1 & \textbf{0.77} & 0.69 & \textbf{0.5} & 0.47 & \textbf{0.75} & 0.71 & \textbf{0.53} &\multicolumn{2}{c}{ \textbf{0.53}  } \\ 
			SmartPhone$^{1}$ & 1 & \textbf{0.71} & \textbf{0.71} & 0.69 & \textbf{0.71} & \textbf{0.71} & \textbf{0.71} & \textbf{0.71} &\multicolumn{2}{c}{ \textbf{0.71}  } \\ 
			Zenotravel & 1 & \textbf{1.0} & \textbf{1.0} & 0.63 & \textbf{1.0} & \textbf{1.0} & \textbf{1.0} & 0.83 &\multicolumn{2}{c}{ \textbf{1.0}  } \\ 
			\midrule 
			IPC score & 12 & 7.1 & \textbf{8.4} & 5.3 & \textbf{6.7} & 7.0 & \textbf{7.9} & 5.8 &\multicolumn{2}{c}{ \textbf{6.7}  } \\
			\bottomrule 
		\end{tabular} 
	}
\end{table*}



\begin{table*}
	\centering
	\caption{Coverage achieved, using Simple Inference on Lifted Problems}
	\label{table:LiftedSimpleCoverage}
	\scalebox{0.6} {
		\begin{tabular}{lccccccccccccccccccl} 
			\toprule 
			&& \multicolumn{2}{c}{rc2(Add)} & \multicolumn{2}{c}{rc2(Filter)} & \multicolumn{2}{c}{rc2(FF)} & \multicolumn{2}{c}{rc2(LMC)}  & \multicolumn{2}{c}{Lilotane} & \multicolumn{2}{c}{HyperTensioN} \\  
			\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8} \cmidrule(lr){9-10} \cmidrule(lr){11-12}   \cmidrule(lr){13-14} 
			& max &PO & TO & PO & TO & PO & TO & PO &  TO  \\ 
			\midrule 
			Barman-BDI & 20 & 3.0 & \textbf{10.0} & 3.0 & \textbf{10.0} & 3.0 & \textbf{10.0} & 2.0 & \textbf{9.0} &\multicolumn{2}{c}{ \textbf{17.0}  } \\ 
			Monroe Fully Observ.$^{7,7,7,5,0}$ & 25 & \textbf{25.0} & \textbf{25.0} & 18.0 & \textbf{22.0} & 22.0 & \textbf{23.0} & \textbf{15.0} & \textbf{15.0} &\multicolumn{2}{c}{ 18.0  } \\ 
			Monroe Part. Observ.$^{2,2,2,2,0}$ & 24 & \textbf{14.0} & 13.0 & \textbf{7.0} & 6.0 & \textbf{14.0} & 13.0 & \textbf{11.0} & 9.0 &\multicolumn{2}{c}{ \textbf{20.0}  } \\ 
			PCP$^{18,18,17,17}$ & 18 & \textbf{15.0} & \textbf{15.0} & \textbf{15.0} & \textbf{15.0} & \textbf{14.0} & \textbf{14.0} & \textbf{14.0} & \textbf{14.0} &\multicolumn{2}{c}{ 0.0  } \\ 
			Rover & 20 & 6.0 & \textbf{15.0} & 4.0 & \textbf{13.0} & 4.0 & \textbf{14.0} & 4.0 & \textbf{13.0} &\multicolumn{2}{c}{ \textbf{20.0}  } \\ 
			Satellite & 25 & 24.0 & \textbf{25.0} & 22.0 & \textbf{25.0} & \textbf{25.0} & \textbf{25.0} & 24.0 & \textbf{25.0} &\multicolumn{2}{c}{ \textbf{25.0}  } \\ 
			Transport & 40 & 12.0 & \textbf{27.0} & \textbf{2.0} & \textbf{2.0} & 13.0 & \textbf{14.0} & 7.0 & \textbf{12.0} &\multicolumn{2}{c}{ \textbf{35.0}  } \\ 
			UM-Translog$^{1,1,1,1,0}$ & 22 & \textbf{22.0} & \textbf{22.0} & \textbf{22.0} & \textbf{22.0} & \textbf{22.0} & \textbf{22.0} & \textbf{22.0} & \textbf{22.0} &\multicolumn{2}{c}{ 21.0  } \\ 
			Woodworking & 30 & \textbf{13.0} & 7.0 & \textbf{8.0} & 7.0 & \textbf{12.0} & 7.0 & \textbf{9.0} & 7.0 &\multicolumn{2}{c}{ 6.0  } \\ 
			\midrule 
			Monroe & 100 & \textbf{96.0} & 92.0 & 79.0 & \textbf{87.0} & \textbf{92.0} & 90.0 & 81.0 & \textbf{89.0} &\multicolumn{2}{c}{ \textbf{100.0}  } \\ 
			SmartPhone$^{3,3,3,3,0}$ & 7 & 5.0 & \textbf{7.0} & 5.0 & \textbf{6.0} & 5.0 & \textbf{6.0} & 5.0 & \textbf{6.0} &\multicolumn{2}{c}{ 1.0  } \\ 
			Zenotravel & 5 & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} & \textbf{5.0} &\multicolumn{2}{c}{ \textbf{5.0}  } \\ 
			\midrule 
			Coverage & 336 & 240.0 & \textbf{263.0} & 190.0 & \textbf{220.0} & 231.0 & \textbf{243.0} & 199.0 & \textbf{226.0} &\multicolumn{2}{c}{ \textbf{268.0}  } \\ 
			Norm. coverage & 12 & 8.23 & \textbf{9.45} & 6.9 & \textbf{8.12} & 8.0 & \textbf{8.83} & 7.14 & \textbf{8.18} &\multicolumn{2}{c}{ 8.58  } \\ 
			\bottomrule 
		\end{tabular} 
	}
\end{table*}




\begin{table*}
	\centering
	\caption{IPC score achieved, using Simple Inference on Lifted Problems}
	\label{table:LiftedSimpleIPC}
	\scalebox{0.6} {
		\begin{tabular}{lccccccccccccccccccl} 
			\toprule 
			&& \multicolumn{2}{c}{rc2(Add)} & \multicolumn{2}{c}{rc2(Filter)} & \multicolumn{2}{c}{rc2(FF)} & \multicolumn{2}{c}{rc2(LMC)}  & \multicolumn{2}{c}{Lilotane} & \multicolumn{2}{c}{HyperTensioN} \\ 
			\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8} \cmidrule(lr){9-10} \cmidrule(lr){11-12}   \cmidrule(lr){13-14} 
			& max &PO & TO & PO & TO & PO & TO & PO & TO   \\ 
			\midrule 
			Barman-BDI & 1 & 0.07 & \textbf{0.38} & 0.07 & \textbf{0.34} & 0.07 & \textbf{0.35} & 0.05 & \textbf{0.23} &\multicolumn{2}{c}{ \textbf{0.72}  } \\ 
			Monroe Fully Observ.$^{7,7,7,5,0}$ & 1 & \textbf{0.56} & 0.52 & 0.32 & \textbf{0.33} & \textbf{0.47} & 0.45 & \textbf{0.22} & 0.21 &\multicolumn{2}{c}{ 0.54  } \\ 
			Monroe Part. Observ.$^{2,2,2,2,0}$ & 1 & \textbf{0.31} & 0.28 & \textbf{0.14} & 0.13 & \textbf{0.31} & 0.29 & \textbf{0.17} & 0.16 &\multicolumn{2}{c}{ \textbf{0.63}  } \\ 
			PCP$^{18,18,17,17}$ & 1 & \textbf{0.83} & \textbf{0.83} & \textbf{0.83} & \textbf{0.83} & \textbf{0.82} & \textbf{0.82} & \textbf{0.82} & \textbf{0.82} &\multicolumn{2}{c}{ 0.0  } \\ 
			Rover & 1 & 0.28 & \textbf{0.61} & 0.14 & \textbf{0.49} & 0.2 & \textbf{0.56} & 0.17 & \textbf{0.42} &\multicolumn{2}{c}{ \textbf{0.97}  } \\ 
			Satellite & 1 & 0.9 & \textbf{1.0} & 0.76 & \textbf{1.0} & 0.99 & \textbf{1.0} & 0.89 & \textbf{0.99} &\multicolumn{2}{c}{ \textbf{1.0}  } \\ 
			Transport & 1 & 0.24 & \textbf{0.6} & 0.04 & \textbf{0.05} & 0.27 & \textbf{0.32} & 0.12 & \textbf{0.2} &\multicolumn{2}{c}{ \textbf{0.78}  } \\ 
			UM-Translog$^{1,1,1,1,0}$ & 1 & \textbf{1.0} & 0.99 & \textbf{1.0} & \textbf{1.0} & \textbf{1.0} & \textbf{1.0} & \textbf{1.0} & \textbf{1.0} &\multicolumn{2}{c}{ 0.92  } \\ 
			Woodworking & 1 & \textbf{0.38} & 0.23 & 0.2 & \textbf{0.23} & \textbf{0.36} & 0.23 & \textbf{0.27} & 0.23 &\multicolumn{2}{c}{ 0.2  } \\ 
			\midrule 
			Monroe & 1 & \textbf{0.77} & 0.74 & \textbf{0.5} & 0.47 & \textbf{0.76} & 0.73 & \textbf{0.54} & 0.51 &\multicolumn{2}{c}{ \textbf{0.96}  } \\ 
			SmartPhone$^{3,3,3,3,0}$ & 1 & 0.71 & \textbf{1.0} & 0.69 & \textbf{0.85} & 0.71 & \textbf{0.86} & 0.71 & \textbf{0.83} &\multicolumn{2}{c}{ 0.14  } \\  
			Zenotravel & 1 & \textbf{1.0} & \textbf{1.0} & 0.64 & \textbf{1.0} & \textbf{1.0} & \textbf{1.0} & 0.83 & \textbf{1.0} &\multicolumn{2}{c}{ \textbf{1.0}  } \\ 
			\midrule 
			IPC score & 12 & 7.1 & \textbf{8.2} & 5.3 & \textbf{6.7} & 7.0 & \textbf{7.6} & 5.8 & \textbf{6.6} &\multicolumn{2}{c}{ 7.9  } \\ 
			\bottomrule 
		\end{tabular} 
	}
\end{table*} 



\begin{table*}
	\centering
	\caption{Coverage achieved, using Complex Inference}
	\label{table:GroundedComplexCoverage}.
	\scalebox{0.8} {
		\begin{tabular}{lccccccccccccccccl} 
			\toprule 
			&& \multicolumn{2}{c}{rc2(Add)} & \multicolumn{2}{c}{rc2(Filter)} & \multicolumn{2}{c}{rc2(FF)} & \multicolumn{2}{c}{rc2(LMC)} & \multicolumn{2}{c}{HyperTensioN} & \multicolumn{2}{c}{Lilotane} \\ 
			\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8} \cmidrule(lr){9-10}     \cmidrule(lr){11-12} \cmidrule(lr){13-14}  
			& max &PO & TO & PO & TO & PO & TO & PO & TO \\ 
			\midrule 
			Barman-BDI  \\ 
			Monroe Fully Observ.$^{2}$   \\ 
			Monroe Part. Observ.$^{2}$  \\ 
			PCP$^{17}$  \\ 
			Rover  \\ 
			Satellite   \\  
			Transport   \\ 
			UM-Translog$^{1}$  \\ 
			Woodworking$^{2}$  \\ 
			\midrule 
			Monroe   \\ 
			SmartPhone$^{1}$   \\ 
			Zenotravel   \\ 
			\midrule 
			Coverage  \\ 
			Norm. coverage  \\ 
			\bottomrule 
		\end{tabular}  
	}
\end{table*}

\begin{table*}
	\centering
	\caption{IPC score achieved, using Complex Inference}
	\label{table:GroundedComplexIPC}.
	\scalebox{0.8} {
		\begin{tabular}{lccccccccccccccccl} 
			\toprule 
&& \multicolumn{2}{c}{rc2(Add)} & \multicolumn{2}{c}{rc2(Filter)} & \multicolumn{2}{c}{rc2(FF)} & \multicolumn{2}{c}{rc2(LMC)} & \multicolumn{2}{c}{HyperTensioN} & \multicolumn{2}{c}{Lilotane} \\ 
\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8} \cmidrule(lr){9-10}   \cmidrule(lr){11-12} \cmidrule(lr){13-14}  
& max &PO & TO & PO & TO & PO & TO & PO & TO \\ 
\midrule 
Barman-BDI  \\ 
Monroe Fully Observ.$^{2}$   \\ 
Monroe Part. Observ.$^{2}$  \\ 
PCP$^{17}$  \\ 
Rover  \\ 
Satellite   \\  
Transport   \\ 
UM-Translog$^{1}$  \\ 
Woodworking$^{2}$  \\ 
\midrule 
Monroe   \\ 
SmartPhone$^{1}$   \\ 
Zenotravel   \\ 
\midrule 
IPC score \\
\bottomrule 
\end{tabular}  
	}
\end{table*}





%\begin{figure*}
%	\caption{Percentage of Problems Linearized Without Cycle-break for each Domain and each Inference Method}
%	\label{fig:ProblemsLinearizedWOCycleBreak}
%	\centering
%	\includegraphics[width=14cm]{figures/Lin_criteria_C_vs_S.jpg}
%\end{figure*}


\begin{figure*}
	\caption{For Grounded Problems, Average Percentage of Methods Linearized Without Cycle-break for Each Domain and for Each Inference Method}
	\label{fig:MethodsLinearizedWOCycleBreak}
	\centering
	\includegraphics[width=14cm]{figures/Lin_average_C_vs_S.jpg}
\end{figure*} 


\section{Future Work}
%Encode Linearization Problem as a MAX-SAT Problem
The maximum satisfiability problem (MAX-SAT) is the problem of determining the maximum number of clauses, of a given Boolean formula in conjunctive normal form, that can be made true by an assignment of truth values to the variables of the formula. MAX-SAT is used over SAT as it may not be possible to satisfy all orderings implied by the inferred preconditions and effects.

The current linearization procedure considers each method in isolation, and sub-tasks have their inferred $\PreS, \AddS, \DelS$. Thus we can treat each sub-task as a \enquote{action}, and encode the method the same way as a classical plan, similar to the one described by \cite{RINTANEN201245}, but with the additional constraint that \enquote{actions} chosen from the method sub-tasks can only be selected once, unlike in the domain. Assuming no negative preconditons, the initial state has all state variables true, and goal state can be assumed to be empty (i.e.\ all state variables can have any assignment). The relative success (or failure) of this approach could also lend insight into what about the criteria causes the linearization to be successful.


%Adding a Plan as Additional Input to the Domain
Adding a plan as additional input to the PO domain having the
semantics that this plan shall be in the solution set of the TO output
model. This reduces the computational complexity of the decision problem from undecidable to something decidable. The specific complexity class of this will have to be proven in further work.  % I assume the resulting problem is PSPACE-complete, but this needs to be proven





\section{Conclusion}

% The contributions of this paper are as follows:

This paper finds that, at least for the POHTN problems in the IPC domain, most of them are not undecidable. In other words, it is as if the POHTN domains are compressed TO domains - this linearization separates one of them back out.

We can also see this pre-processing technique leads to large gains in time/efficiency for a number of planners, at least for the problems tested here. Furthermore, there is demonstrably much more room for improvement. Though the criteria does not fire all the time, it's producing a linearization that is almost always solvable.

This method can also be used to increase the number of TOHTN problems available for purposes like comparing TOHTN planners or grounding techniques. Suppose there were $n$ POHTN problms and $m$ TOHTN problems, and this linearization could make those $n$ POHTN problems into $k$ solvable $TOHTN$ problems. Then $k+m$ (lifted or grounded) TOHTN problems exist now. And from empirical evaluation, $k$ may be close to $n$.

Finally, in this paper we identify a subset of decidable problems within POHTN problems, and this subset is orthogonal to all others discussed in other works.









% Use \bibliography{yourbibfile} instead or the References section will not appear in your paper
\bibliography{bib}
% \nobibliography{aaai22}

\end{document}
